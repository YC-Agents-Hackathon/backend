### Detective LLM Backend – MVP PRD

#### Overview
Backend to power a multi-thread detective assistant. Each "thread" is identified by `notebookId`. Evidence is uploaded per `notebookId` and appended to its context. Users can chat (non-stream or SSE stream) with an investigator persona and request a plain text report generated by a report persona. No auth, no versioning.

#### Assumptions
- **Auth**: none
- **Versioning**: none (base URL: `http://localhost:8000`)
- **Tenancy**: `notebookId` is the sole thread identifier; notebooks auto-create on first use
- **Persistence**: in-memory singleton for MVP
- **Model params**: not exposed; server-side default model
- **Citations**: none; outputs are plain text

#### In-memory state shape (server)
```ts
type Message = { role: 'user' | 'assistant'; content: string; ts: number };
type NotebookState = {
  evidence: string[];        // appended-only per upload call
  messages: Message[];       // chat history for that notebook
};
type Store = Record<string /* notebookId */, NotebookState>;
```

#### System prompts (server-side)
- **Investigator Persona**
  - Purpose: interactive copilot to analyze evidence and user questions.
  - Prompt: "You are a meticulous detective AI assisting an investigation. Use only the provided evidence and conversation. Be concise, actionable, and avoid speculation. If information is missing, ask a short clarifying question. Prefer bullet points and short paragraphs. Do not cite sources. Keep responses under 200 words."

- **Report Persona**
  - Purpose: produce a final readable report summarizing the case.
  - Prompt: "You are a seasoned detective writing a clear narrative report for non-technical readers. Summarize facts, key actors, likely sequence of events, and remaining unknowns. Keep it confident but avoid speculation. Do not cite sources. Output plain text with short section headers (Summary, Timeline, Key Actors, Evidence Highlights, Open Questions, Next Steps). Keep under 800 words."

---

## Endpoints

### Health
- **GET** `/health`
- 200 → `{ "status": "healthy" }`

### Upload Evidence (append-only)
- **POST** `/api/upload`
- **Body**
```ts
interface UploadRequest {
  notebookId: string;      // arbitrary string; auto-creates notebook if new
  evidence: string[];      // appended to existing evidence; empty array is no-op
}
```
- **Response**
```ts
interface UploadResponse {
  notebookId: string;
  totalEvidenceCount: number;  // count after append
}
```
- **Notes**: server concatenates evidence internally when building context; no size guarantees in MVP.

### Chat (non-streaming)
- **POST** `/api/chat`
- **Body**
```ts
interface ChatRequest {
  notebookId: string;
  userMessage: string;
}
```
- **Response**
```ts
interface ChatResponse {
  response: string;        // assistant reply (investigator persona)
}
```
- **Behavior**: server builds system message = Investigator Persona + joined evidence; includes prior messages for `notebookId`.

### Chat (SSE streaming)
- **POST** `/api/chat/stream`
- **Headers**: `Accept: text/event-stream`
- **Body**: `ChatRequest` (same as above)
- **Events** (SSE `data:` lines)
```ts
type ChatStreamEvent =
  | { type: 'content'; content: string }   // token/chunk content
  | { type: 'final'; content: string }     // final assembled text
  | { type: 'done' }
  | { type: 'error'; error: string };
```

### Generate Report (non-streaming)
- **POST** `/api/report`
- **Body**
```ts
interface ReportRequest {
  notebookId: string;     // uses all evidence and chat history for this notebook
  task?: string;          // optional short goal e.g. "Draft final incident report"
}
```
- **Response**
```ts
interface ReportResponse {
  report: string;         // plain text, sectioned by the persona prompt
}
```
- **Behavior**: server builds system message = Report Persona + joined evidence + brief synopsis of chat history.

---

## Error shape (all endpoints)
```ts
interface ErrorResponse { error: string }
```
- 400: invalid body
- 500: internal error
- Unknown `notebookId` auto-creates with empty evidence/messages

---

## Example requests

Upload
```http
POST /api/upload
Content-Type: application/json

{
  "notebookId": "case-42",
  "evidence": [
    "Camera footage shows a red sedan at 21:14 near Oak St.",
    "Witness says suspect wore a blue jacket."]
}
```

Chat (non-stream)
```http
POST /api/chat
Content-Type: application/json

{ "notebookId": "case-42", "userMessage": "What are the top 3 leads?" }
```

Chat (SSE)
```http
POST /api/chat/stream
Accept: text/event-stream
Content-Type: application/json

{ "notebookId": "case-42", "userMessage": "Cross-check car and jacket details." }
```

Report
```http
POST /api/report
Content-Type: application/json
(no input)
```

---

## Implementation notes (server)
- Fixed default model (e.g., "openai/gpt-4o-mini")
- System prompts are not client-configurable
- Evidence joined with newlines to form context
- Messages stored as `{ role, content, ts }` and included on subsequent chats